{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "green-compression",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/stable_baselines3/common/cmd_util.py:6: FutureWarning: Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\n",
      "  \"Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from env import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "orange-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hard cases for training found\n",
      "2 hard cases for training found\n",
      "3 hard cases for training found\n",
      "4 hard cases for training found\n",
      "5 hard cases for training found\n",
      "6 hard cases for training found\n",
      "7 hard cases for training found\n",
      "8 hard cases for training found\n",
      "9 hard cases for training found\n",
      "10 hard cases for training found\n",
      "11 hard cases for training found\n",
      "12 hard cases for training found\n",
      "13 hard cases for training found\n",
      "14 hard cases for training found\n",
      "15 hard cases for training found\n",
      "16 hard cases for training found\n",
      "17 hard cases for training found\n",
      "18 hard cases for training found\n",
      "19 hard cases for training found\n",
      "20 hard cases for training found\n",
      "21 hard cases for training found\n",
      "22 hard cases for training found\n",
      "23 hard cases for training found\n",
      "24 hard cases for training found\n",
      "25 hard cases for training found\n",
      "26 hard cases for training found\n",
      "27 hard cases for training found\n",
      "28 hard cases for training found\n",
      "29 hard cases for training found\n",
      "30 hard cases for training found\n",
      "31 hard cases for training found\n",
      "32 hard cases for training found\n",
      "33 hard cases for training found\n",
      "34 hard cases for training found\n",
      "35 hard cases for training found\n",
      "36 hard cases for training found\n",
      "37 hard cases for training found\n",
      "38 hard cases for training found\n",
      "39 hard cases for training found\n",
      "40 hard cases for training found\n",
      "41 hard cases for training found\n",
      "42 hard cases for training found\n",
      "43 hard cases for training found\n",
      "44 hard cases for training found\n",
      "45 hard cases for training found\n",
      "46 hard cases for training found\n",
      "47 hard cases for training found\n",
      "48 hard cases for training found\n",
      "49 hard cases for training found\n",
      "50 hard cases for training found\n",
      "51 hard cases for training found\n",
      "52 hard cases for training found\n",
      "53 hard cases for training found\n",
      "54 hard cases for training found\n",
      "55 hard cases for training found\n",
      "56 hard cases for training found\n",
      "57 hard cases for training found\n",
      "58 hard cases for training found\n",
      "59 hard cases for training found\n",
      "60 hard cases for training found\n",
      "61 hard cases for training found\n",
      "62 hard cases for training found\n",
      "63 hard cases for training found\n",
      "64 hard cases for training found\n",
      "65 hard cases for training found\n",
      "66 hard cases for training found\n",
      "67 hard cases for training found\n",
      "68 hard cases for training found\n",
      "69 hard cases for training found\n",
      "70 hard cases for training found\n",
      "71 hard cases for training found\n",
      "72 hard cases for training found\n",
      "73 hard cases for training found\n",
      "74 hard cases for training found\n",
      "75 hard cases for training found\n",
      "76 hard cases for training found\n",
      "77 hard cases for training found\n",
      "78 hard cases for training found\n",
      "79 hard cases for training found\n",
      "80 hard cases for training found\n",
      "81 hard cases for training found\n",
      "82 hard cases for training found\n",
      "83 hard cases for training found\n",
      "84 hard cases for training found\n",
      "85 hard cases for training found\n",
      "86 hard cases for training found\n",
      "87 hard cases for training found\n",
      "88 hard cases for training found\n",
      "89 hard cases for training found\n",
      "90 hard cases for training found\n",
      "91 hard cases for training found\n",
      "92 hard cases for training found\n",
      "93 hard cases for training found\n",
      "94 hard cases for training found\n",
      "95 hard cases for training found\n",
      "96 hard cases for training found\n",
      "97 hard cases for training found\n",
      "98 hard cases for training found\n",
      "99 hard cases for training found\n",
      "100 hard cases for training found\n"
     ]
    }
   ],
   "source": [
    "### generate train environments ###\n",
    "env_train_num = 100\n",
    "opt_num = 10\n",
    "sup_dim = 100\n",
    "ob_num = 10\n",
    "limit = np.array([10,20])\n",
    "lr = 0.1\n",
    "\n",
    "### generate hard train environments ###\n",
    "random.seed(0)\n",
    "env_train_hard_list1 = []\n",
    "count = 0\n",
    "while(count<env_train_num):\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    free = False\n",
    "    for j in range(200):\n",
    "        x0 = x0 - lr*env_try.obj.ob_der_fun(x0)\n",
    "    if not env_try.obj.collision(x0):\n",
    "        env_train_hard_list1.append(env_try)\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(count,'hard cases for training found')\n",
    "    env_try.close()\n",
    "env_train_hard_list = [make_env(env,i) for i,env in enumerate(env_train_hard_list1)]\n",
    "env_train_hard = DummyVecEnv(env_train_hard_list)\n",
    "\n",
    "### generate easy train environments ###\n",
    "env_train_easy_list1 = []\n",
    "for i in range(env_train_num):\n",
    "    env_train_easy_list1.append(generate_env(ob_num,limit,opt_num,sup_dim))\n",
    "env_train_easy_list = [make_env(env,i) for i,env in enumerate(env_train_easy_list1)]\n",
    "env_train_easy = DummyVecEnv(env_train_easy_list)\n",
    "### generate mixed train environments ###\n",
    "env_train_mix_list1 = env_train_easy_list1[0:50] + env_train_hard_list1[0:50]\n",
    "env_train_mix_list = [make_env(env,i) for i,env in enumerate(env_train_mix_list1)]\n",
    "env_train_mix = DummyVecEnv(env_train_mix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate supervision data ###\n",
    "# train the agent in easy/hard benchmark\n",
    "env_train = env_train_easy\n",
    "\n",
    "exp_data = env_train.env_method('supervision')\n",
    "exp_obs = [i[0] for i in exp_data]\n",
    "exp_act = [i[1] for i in exp_data]\n",
    "exp_obs = np.concatenate(exp_obs).astype(np.float32)\n",
    "exp_act = np.concatenate(exp_act).astype(np.float32)\n",
    "\n",
    "exp_data = ExpertDataSet(exp_obs, exp_act)\n",
    "train_size = int(0.8 * len(exp_data))\n",
    "test_size = len(exp_data) - train_size\n",
    "exp_train, exp_test = random_split(exp_data, [train_size, test_size])\n",
    "### generate supervision data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handmade-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Train Epoch: 1 [0/8000 (0%)]\tLoss: 1.024513\n",
      "Test set: Average loss: 0.0002\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 219  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 4000 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 198        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 8000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03441817 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.7      |\n",
      "|    explained_variance   | -1.98e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.12e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    std                  | 0.679      |\n",
      "|    value_loss           | 1.06e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029578002 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | -2.05e+03   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.68e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    std                  | 0.678       |\n",
      "|    value_loss           | 1.32e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 191        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02675662 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.6      |\n",
      "|    explained_variance   | -2.11e+05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4e+03      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    std                  | 0.675      |\n",
      "|    value_loss           | 1.27e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 190         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028045965 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | -8.81e+05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.32e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.675       |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 24000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028704679 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | -2.78e+06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.18e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 1.12e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 188         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 28000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039246462 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | -2.52e+07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 0.673       |\n",
      "|    value_loss           | 9.49e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 188        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 32000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03635078 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.4      |\n",
      "|    explained_variance   | -7.47e+07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.08e+03   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    std                  | 0.671      |\n",
      "|    value_loss           | 9.68e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 36000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047723606 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | -2.69e+08   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.63e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 8.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041915085 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | -4.44e+08   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 7.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 187        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 44000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04541618 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.2      |\n",
      "|    explained_variance   | -6.1e+08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.29e+03   |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    std                  | 0.664      |\n",
      "|    value_loss           | 7.34e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 187        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 48000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06128595 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.1      |\n",
      "|    explained_variance   | -1.56e+08  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.29e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    std                  | 0.66       |\n",
      "|    value_loss           | 8.26e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 187       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 277       |\n",
      "|    total_timesteps      | 52000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0914266 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -20       |\n",
      "|    explained_variance   | -7.9e+09  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.66e+03  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -0.0211   |\n",
      "|    std                  | 0.657     |\n",
      "|    value_loss           | 7.82e+03  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_new_model = True\n",
    "if train_new_model:\n",
    "    student = PPO(CustomActorCriticPolicy, env_train, n_steps = 40, gamma=1, verbose=1)\n",
    "    pretrain_agent(\n",
    "        student,\n",
    "        exp_train = exp_train,\n",
    "        exp_test = exp_test,\n",
    "        epochs=1,\n",
    "        scheduler_gamma=0.7,\n",
    "        learning_rate=1.0,\n",
    "        log_interval=1000,\n",
    "        no_cuda=False,\n",
    "        seed=1,\n",
    "        batch_size=64)\n",
    "    student.policy.float()\n",
    "    student.learn(50000)\n",
    "    student.save('obs_orig/easy_0.1_128_50k')\n",
    "else:\n",
    "    # load existing model\n",
    "    student = PPO.load('obs_orig/mix_reward_0.1_PN64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run time evalution env found\n",
      "2 run time evalution env found\n",
      "3 run time evalution env found\n",
      "4 run time evalution env found\n",
      "5 run time evalution env found\n",
      "6 run time evalution env found\n",
      "7 run time evalution env found\n",
      "8 run time evalution env found\n",
      "9 run time evalution env found\n",
      "10 run time evalution env found\n",
      "11 run time evalution env found\n",
      "12 run time evalution env found\n",
      "13 run time evalution env found\n",
      "14 run time evalution env found\n",
      "15 run time evalution env found\n",
      "16 run time evalution env found\n",
      "17 run time evalution env found\n",
      "18 run time evalution env found\n",
      "19 run time evalution env found\n",
      "20 run time evalution env found\n",
      "21 run time evalution env found\n",
      "22 run time evalution env found\n",
      "23 run time evalution env found\n",
      "24 run time evalution env found\n",
      "25 run time evalution env found\n",
      "26 run time evalution env found\n",
      "27 run time evalution env found\n",
      "28 run time evalution env found\n",
      "29 run time evalution env found\n",
      "30 run time evalution env found\n",
      "31 run time evalution env found\n",
      "32 run time evalution env found\n",
      "33 run time evalution env found\n",
      "34 run time evalution env found\n",
      "35 run time evalution env found\n",
      "36 run time evalution env found\n",
      "37 run time evalution env found\n",
      "38 run time evalution env found\n",
      "39 run time evalution env found\n",
      "40 run time evalution env found\n",
      "41 run time evalution env found\n",
      "42 run time evalution env found\n",
      "43 run time evalution env found\n",
      "44 run time evalution env found\n",
      "45 run time evalution env found\n",
      "46 run time evalution env found\n",
      "47 run time evalution env found\n",
      "48 run time evalution env found\n",
      "49 run time evalution env found\n",
      "50 run time evalution env found\n",
      "51 run time evalution env found\n",
      "52 run time evalution env found\n",
      "53 run time evalution env found\n",
      "54 run time evalution env found\n",
      "55 run time evalution env found\n",
      "56 run time evalution env found\n",
      "57 run time evalution env found\n",
      "58 run time evalution env found\n",
      "59 run time evalution env found\n",
      "60 run time evalution env found\n",
      "61 run time evalution env found\n",
      "62 run time evalution env found\n",
      "63 run time evalution env found\n",
      "64 run time evalution env found\n",
      "65 run time evalution env found\n",
      "66 run time evalution env found\n",
      "67 run time evalution env found\n",
      "68 run time evalution env found\n",
      "69 run time evalution env found\n",
      "70 run time evalution env found\n",
      "71 run time evalution env found\n",
      "72 run time evalution env found\n",
      "73 run time evalution env found\n",
      "74 run time evalution env found\n",
      "75 run time evalution env found\n",
      "76 run time evalution env found\n",
      "77 run time evalution env found\n",
      "78 run time evalution env found\n",
      "79 run time evalution env found\n",
      "80 run time evalution env found\n",
      "81 run time evalution env found\n",
      "82 run time evalution env found\n",
      "83 run time evalution env found\n",
      "84 run time evalution env found\n",
      "85 run time evalution env found\n",
      "86 run time evalution env found\n",
      "87 run time evalution env found\n",
      "88 run time evalution env found\n",
      "89 run time evalution env found\n",
      "90 run time evalution env found\n",
      "91 run time evalution env found\n",
      "92 run time evalution env found\n",
      "93 run time evalution env found\n",
      "94 run time evalution env found\n",
      "95 run time evalution env found\n",
      "96 run time evalution env found\n",
      "97 run time evalution env found\n",
      "98 run time evalution env found\n",
      "99 run time evalution env found\n",
      "100 run time evalution env found\n"
     ]
    }
   ],
   "source": [
    "## runtime evaluation \n",
    "runtime_env_num = 100\n",
    "ob_num = 10\n",
    "limit = np.array([10,20])\n",
    "opt_num = 10\n",
    "sup_dim = 0\n",
    "# generate run time evaluation environments\n",
    "random.seed(1)\n",
    "time_env_list1 = []\n",
    "count = 0\n",
    "while(count < runtime_env_num):\n",
    "    done1 = False \n",
    "    done = False\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    obs = env_try.reset()\n",
    "    for j in range(100):\n",
    "        x0 = x0 - 0.1*env_try.obj.ob_der_fun(x0)\n",
    "        if env_try.obj.collision(x0):\n",
    "            done1 = True\n",
    "            break\n",
    "    for k in range(100):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_try.step(action)\n",
    "        if done:\n",
    "            break\n",
    "    if done1 and done and j > 10:\n",
    "        time_env_list1.append(env_try)\n",
    "        count += 1\n",
    "        print(count,'run time evalution env found')\n",
    "    env_try.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experimental-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.214087724685669 1.8839995861053467\n",
      "===========================================================\n",
      "\n",
      "GD success rate: 1.0 GD average iterations= 26.56\n",
      "RL success rate: 1.0 RL average iterations= 18.04\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env = time_env_list1[1]\n",
    "x0 = env.obj.initial()\n",
    "obs = env.reset()\n",
    "ob_der_fun = env.obj.ob_der_fun\n",
    "t1 = time.time()\n",
    "for j in range(1000):\n",
    "    x0 = x0 - lr*ob_der_fun(x0)\n",
    "t_gd = time.time()-t1\n",
    "t1 = time.time()\n",
    "for j in range(1000):\n",
    "    action, _ = student.predict(obs, deterministic=True)\n",
    "    env.pos = action.reshape(10,2) + env.pos\n",
    "    obs = env.obj.ob_der_fun(env.pos).flatten()\n",
    "t_rl = time.time()-t1\n",
    "print(t_gd,t_rl)\n",
    "runtime(student, time_env_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyzed-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hard cases for test found\n",
      "2 hard cases for test found\n",
      "3 hard cases for test found\n",
      "4 hard cases for test found\n",
      "5 hard cases for test found\n",
      "6 hard cases for test found\n",
      "7 hard cases for test found\n",
      "8 hard cases for test found\n",
      "9 hard cases for test found\n",
      "10 hard cases for test found\n",
      "11 hard cases for test found\n",
      "12 hard cases for test found\n",
      "13 hard cases for test found\n",
      "14 hard cases for test found\n",
      "15 hard cases for test found\n",
      "16 hard cases for test found\n",
      "17 hard cases for test found\n",
      "18 hard cases for test found\n",
      "19 hard cases for test found\n",
      "20 hard cases for test found\n",
      "21 hard cases for test found\n",
      "22 hard cases for test found\n",
      "23 hard cases for test found\n",
      "24 hard cases for test found\n",
      "25 hard cases for test found\n",
      "26 hard cases for test found\n",
      "27 hard cases for test found\n",
      "28 hard cases for test found\n",
      "29 hard cases for test found\n",
      "30 hard cases for test found\n",
      "31 hard cases for test found\n",
      "32 hard cases for test found\n",
      "33 hard cases for test found\n",
      "34 hard cases for test found\n",
      "35 hard cases for test found\n",
      "36 hard cases for test found\n",
      "37 hard cases for test found\n",
      "38 hard cases for test found\n",
      "39 hard cases for test found\n",
      "40 hard cases for test found\n",
      "41 hard cases for test found\n",
      "42 hard cases for test found\n",
      "43 hard cases for test found\n",
      "44 hard cases for test found\n",
      "45 hard cases for test found\n",
      "46 hard cases for test found\n",
      "47 hard cases for test found\n",
      "48 hard cases for test found\n",
      "49 hard cases for test found\n",
      "50 hard cases for test found\n",
      "51 hard cases for test found\n",
      "52 hard cases for test found\n",
      "53 hard cases for test found\n",
      "54 hard cases for test found\n",
      "55 hard cases for test found\n",
      "56 hard cases for test found\n",
      "57 hard cases for test found\n",
      "58 hard cases for test found\n",
      "59 hard cases for test found\n",
      "60 hard cases for test found\n",
      "61 hard cases for test found\n",
      "62 hard cases for test found\n",
      "63 hard cases for test found\n",
      "64 hard cases for test found\n",
      "65 hard cases for test found\n",
      "66 hard cases for test found\n",
      "67 hard cases for test found\n",
      "68 hard cases for test found\n",
      "69 hard cases for test found\n",
      "70 hard cases for test found\n",
      "71 hard cases for test found\n",
      "72 hard cases for test found\n",
      "73 hard cases for test found\n",
      "74 hard cases for test found\n",
      "75 hard cases for test found\n",
      "76 hard cases for test found\n",
      "77 hard cases for test found\n",
      "78 hard cases for test found\n",
      "79 hard cases for test found\n",
      "80 hard cases for test found\n",
      "81 hard cases for test found\n",
      "82 hard cases for test found\n",
      "83 hard cases for test found\n",
      "84 hard cases for test found\n",
      "85 hard cases for test found\n",
      "86 hard cases for test found\n",
      "87 hard cases for test found\n",
      "88 hard cases for test found\n",
      "89 hard cases for test found\n",
      "90 hard cases for test found\n",
      "91 hard cases for test found\n",
      "92 hard cases for test found\n",
      "93 hard cases for test found\n",
      "94 hard cases for test found\n",
      "95 hard cases for test found\n",
      "96 hard cases for test found\n",
      "97 hard cases for test found\n",
      "98 hard cases for test found\n",
      "99 hard cases for test found\n",
      "100 hard cases for test found\n"
     ]
    }
   ],
   "source": [
    "# successful rate evaluation\n",
    "env_test_easy_num = 1000\n",
    "env_test_hard_num = 100\n",
    "\n",
    "# generate easy test environments\n",
    "random.seed(2)\n",
    "env_test_easy_list1 = []\n",
    "for i in range(env_test_easy_num):\n",
    "    env_test_easy_list1.append(generate_env(ob_num,limit,opt_num,0))\n",
    "# generate hard test environments\n",
    "env_test_hard_list1 = []\n",
    "count = 0\n",
    "while(count<env_test_hard_num):\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    free = False\n",
    "    for j in range(200):\n",
    "        x0 = x0 - lr*env_try.obj.ob_der_fun(x0)\n",
    "        if env_try.obj.collision(x0):\n",
    "            free = True\n",
    "            break\n",
    "    if not free:\n",
    "        env_test_hard_list1.append(env_try)\n",
    "        count += 1\n",
    "        print(count,'hard cases for test found')\n",
    "    env_try.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "played-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 complete\n",
      "0.1 complete\n",
      "0.15 complete\n",
      "0.2 complete\n",
      "0.25 complete\n",
      "0.3 complete\n",
      "0.35 complete\n",
      "0.4 complete\n",
      "0.45 complete\n",
      "0.5 complete\n",
      "0.55 complete\n",
      "0.6 complete\n",
      "0.65 complete\n",
      "0.7 complete\n",
      "0.75 complete\n",
      "0.8 complete\n",
      "0.85 complete\n",
      "0.9 complete\n",
      "0.95 complete\n",
      "1.0 complete\n",
      "result_list_easy: [0.737 0.169 0.075 0.019]\n",
      "success_rl: 81.20%\n",
      "success_gd: 75.60%\n"
     ]
    }
   ],
   "source": [
    "### easy test benchmark ###\n",
    "n_steps = 200\n",
    "lr = 0.1\n",
    "result_easy = np.zeros((4,))\n",
    "i = 0\n",
    "for env_test in env_test_easy_list1:\n",
    "    obs = env_test.reset()\n",
    "    x0 = env_test.pos\n",
    "    for step in range(n_steps):\n",
    "        x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "    for step in range(n_steps):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_test.step(action)\n",
    "        if done:\n",
    "            #print(\"Goal reached!\", \"reward=\", reward,\"step=\",step)\n",
    "            break\n",
    "    if done and env_test.obj.collision(x0):\n",
    "        result_easy[0] += 1\n",
    "    if not done and not env_test.obj.collision(x0):\n",
    "        result_easy[1] += 1\n",
    "    if done and not env_test.obj.collision(x0):\n",
    "        result_easy[2] += 1\n",
    "    if not done and env_test.obj.collision(x0):\n",
    "        result_easy[3] += 1\n",
    "    env_test.close()\n",
    "    if (i+1) % 50 == 0:\n",
    "        print((i+1)/len(env_test_easy_list1),'complete')\n",
    "    i += 1\n",
    "result_easy /= len(env_test_easy_list1)\n",
    "print(\"result_list_easy:\", result_easy)\n",
    "rl_success = result_easy[0]+result_easy[2]\n",
    "gd_success = result_easy[0]+result_easy[3]\n",
    "print('success_rl: %.2f%%'  % (rl_success*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "silver-skill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_list_hard_GD 0.0\n",
      "result_list_hard_RL 0.23\n"
     ]
    }
   ],
   "source": [
    "### hard test benchmark ###\n",
    "n_steps = 200\n",
    "lr = 0.1\n",
    "result_hard_GD = 0\n",
    "result_hard_RL = 0\n",
    "for env_test in env_test_hard_list1:\n",
    "    obs = env_test.reset()\n",
    "    x0 = env_test.pos\n",
    "    for step in range(n_steps):\n",
    "        x0 = x0 - lr * env_test.obj.ob_der_fun(x0)\n",
    "        if env_test.obj.collision(x0):\n",
    "            result_hard_GD += 1\n",
    "            break\n",
    "            \n",
    "    for step in range(n_steps):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_test.step(action)\n",
    "        if done:\n",
    "            result_hard_RL += 1\n",
    "            break\n",
    "    env_test.close()\n",
    "result_hard_GD /= len(env_test_hard_list1)\n",
    "result_hard_RL /= len(env_test_hard_list1)\n",
    "print(\"result_list_hard_GD\", result_hard_GD)\n",
    "print(\"result_list_hard_RL\", result_hard_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "greater-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d7955bc1456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0menv_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mob_der_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0menv_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mGD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# print('GD finds feasible solution with',i,'trials on',count,'th environment')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/submission/gradient agent/env.py\u001b[0m in \u001b[0;36mcollision\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/submission/gradient agent/env.py\u001b[0m in \u001b[0;36mall_points\u001b[0;34m(self, x, num)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   4569\u001b[0m             \u001b[0;31m# very different from a[:,[0],:] = ...! This changes values so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4570\u001b[0m             \u001b[0;31m# it works likes the second case. (here a[:,0:1,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4571\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4572\u001b[0m         \u001b[0mnumnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4573\u001b[0m         \u001b[0mnewshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'destination'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         raise ValueError('`source` and `destination` arguments must have '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### multi start on easy test benchmark\n",
    "multi_start_num = 5\n",
    "result_multi_start = np.zeros((4,))\n",
    "\n",
    "count = 0\n",
    "for env_test in env_test_easy_list1:\n",
    "    GD = False\n",
    "    RL = False\n",
    "    i=0\n",
    "    while(GD==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "            if env_test.obj.collision(x0):\n",
    "                GD = True\n",
    "                # print('GD finds feasible solution with',i,'trials on',count,'th environment')\n",
    "                break\n",
    "        i += 1\n",
    "    i=0\n",
    "    while(RL==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            action, _ = student.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env_test.step(action)\n",
    "            if done:\n",
    "                RL = True\n",
    "                # print('RL finds feasible solution with',i,'trials on',count,'th environment')\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    if GD == True and RL == True:\n",
    "        result_multi_start[0] += 1\n",
    "    elif GD == False and RL == False:\n",
    "        result_multi_start[1] += 1\n",
    "    elif GD == False and RL == True:\n",
    "        result_multi_start[2] += 1\n",
    "    else: \n",
    "        result_multi_start[3] += 1\n",
    "    if (count+1) % 50 == 0:\n",
    "        print((count+1)/len(env_test_easy_list1),'complete')\n",
    "    count += 1\n",
    "    env_test.close()\n",
    "    \n",
    "result_multi_start /= len(env_test_easy_list1)\n",
    "print(\"result_list_easy_ms:\", result_multi_start)\n",
    "rl_success_multi = result_multi_start[0]+result_multi_start[2]\n",
    "gd_success_multi = result_multi_start[0]+result_multi_start[3]\n",
    "print('success_rl: %.2f%% ' % (rl_success_multi*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success_multi*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "### multi start on hard test benchmark ###\n",
    "multi_start_num = 5\n",
    "result_multi_start = np.zeros((4,))\n",
    "\n",
    "count = 0\n",
    "for env_test in env_test_hard_list1:\n",
    "    GD = False\n",
    "    RL = False\n",
    "    i=0\n",
    "    while(GD==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "            if env_test.obj.collision(x0):\n",
    "                GD = True\n",
    "                break\n",
    "        i += 1\n",
    "    i=0\n",
    "    while(RL==False and i<multi_start_num):\n",
    "        if i ==0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            action, _ = student.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env_test.step(action)\n",
    "            if done:\n",
    "                RL = True\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    if GD == True and RL == True:\n",
    "        result_multi_start[0] += 1\n",
    "    elif GD == False and RL == False:\n",
    "        result_multi_start[1] += 1\n",
    "    elif GD == False and RL == True:\n",
    "        result_multi_start[2] += 1\n",
    "    else: \n",
    "        result_multi_start[3] += 1\n",
    "    if (count+1) % 50 == 0:\n",
    "        print((count+1)/len(env_test_hard_list1),'complete')\n",
    "    count += 1\n",
    "    env_test.close()\n",
    "    \n",
    "result_multi_start /= len(env_test_hard_list1)\n",
    "print(\"result_list_hard_ms:\", result_multi_start)\n",
    "rl_success_multi = result_multi_start[0]+result_multi_start[2]\n",
    "gd_success_multi = result_multi_start[0]+result_multi_start[3]\n",
    "print('success_rl: %.2f%% ' % (rl_success_multi*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success_multi*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-imperial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-stack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-baking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-craft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-southeast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
