{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/stable_baselines3/common/cmd_util.py:6: FutureWarning: Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\n",
      "  \"Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from env import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-philosophy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hard cases for training found\n",
      "20 hard cases for training found\n",
      "30 hard cases for training found\n",
      "40 hard cases for training found\n",
      "50 hard cases for training found\n",
      "60 hard cases for training found\n",
      "70 hard cases for training found\n",
      "80 hard cases for training found\n",
      "90 hard cases for training found\n",
      "100 hard cases for training found\n"
     ]
    }
   ],
   "source": [
    "### generate train environments ###\n",
    "env_train_num = 100\n",
    "opt_num = 10\n",
    "sup_dim = 100\n",
    "ob_num = 10\n",
    "limit = np.array([10,20])\n",
    "lr = 0.1\n",
    "\n",
    "### generate hard train environments ###\n",
    "random.seed(0)\n",
    "env_train_hard_list1 = []\n",
    "count = 0\n",
    "while(count<env_train_num):\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    for j in range(200):\n",
    "        x0 = x0 - lr*env_try.obj.ob_der_fun(x0)\n",
    "    if not env_try.obj.collision(x0):\n",
    "        env_train_hard_list1.append(env_try)\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(count,'hard cases for training found')\n",
    "    env_try.close()\n",
    "env_train_hard_list = [make_env(env,i) for i,env in enumerate(env_train_hard_list1)]\n",
    "env_train_hard = DummyVecEnv(env_train_hard_list)\n",
    "\n",
    "### generate easy train environments ###\n",
    "env_train_easy_list1 = []\n",
    "for i in range(env_train_num):\n",
    "    env_train_easy_list1.append(generate_env(ob_num,limit,opt_num,sup_dim))\n",
    "env_train_easy_list = [make_env(env,i) for i,env in enumerate(env_train_easy_list1)]\n",
    "env_train_easy = DummyVecEnv(env_train_easy_list)\n",
    "### generate mixed train environments ###\n",
    "env_train_mix_list1 = env_train_easy_list1[0:50] + env_train_hard_list1[0:50]\n",
    "env_train_mix_list = [make_env(env,i) for i,env in enumerate(env_train_mix_list1)]\n",
    "env_train_mix = DummyVecEnv(env_train_mix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detailed-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate supervision data ###\n",
    "# train the agent in easy/hard benchmark\n",
    "env_train = env_train_easy\n",
    "\n",
    "exp_data = env_train.env_method('supervision')\n",
    "exp_obs = [i[0] for i in exp_data]\n",
    "exp_act = [i[1] for i in exp_data]\n",
    "exp_obs = np.concatenate(exp_obs).astype(np.float32)\n",
    "exp_act = np.concatenate(exp_act).astype(np.float32)\n",
    "\n",
    "exp_data = ExpertDataSet(exp_obs, exp_act)\n",
    "train_size = int(0.8 * len(exp_data))\n",
    "test_size = len(exp_data) - train_size\n",
    "exp_train, exp_test = random_split(exp_data, [train_size, test_size])\n",
    "### generate supervision data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Train Epoch: 1 [0/8000 (0%)]\tLoss: 1.024473\n",
      "Test set: Average loss: 0.0002\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 214  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 18   |\n",
      "|    total_timesteps | 4000 |\n",
      "-----------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 195       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 8000      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0405347 |\n",
      "|    clip_fraction        | 0.3       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -20.7     |\n",
      "|    explained_variance   | -1.77e+04 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.44e+03  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -0.0372   |\n",
      "|    std                  | 0.678     |\n",
      "|    value_loss           | 1.01e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 190         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034092207 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.6       |\n",
      "|    explained_variance   | -4.57e+03   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.01e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.676       |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 188        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03435061 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.5      |\n",
      "|    explained_variance   | -1.06e+04  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.97e+03   |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    std                  | 0.673      |\n",
      "|    value_loss           | 1.45e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031853758 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.5       |\n",
      "|    explained_variance   | -5.8e+03    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.92e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    std                  | 0.673       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 24000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038035348 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.4       |\n",
      "|    explained_variance   | -1.85e+03   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    std                  | 0.672       |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 185        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 28000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04327083 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -20.4      |\n",
      "|    explained_variance   | -290       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.65e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    std                  | 0.672      |\n",
      "|    value_loss           | 1.04e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040985394 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.4       |\n",
      "|    explained_variance   | -29.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.54e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 1.05e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 36000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054070536 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | -42.1       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.59e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 9.21e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043937407 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.3       |\n",
      "|    explained_variance   | -8.3        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    std                  | 0.666       |\n",
      "|    value_loss           | 8.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 44000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041350614 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.2       |\n",
      "|    explained_variance   | -6.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    std                  | 0.665       |\n",
      "|    value_loss           | 7.77e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042741813 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20.1       |\n",
      "|    explained_variance   | -2.89       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    std                  | 0.661       |\n",
      "|    value_loss           | 7.34e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 183         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 52000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053995583 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -20         |\n",
      "|    explained_variance   | -3.68       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.1e+03     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 0.657       |\n",
      "|    value_loss           | 7.64e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_new_model = True\n",
    "if train_new_model:\n",
    "    student = PPO(CustomActorCriticPolicy, env_train, n_steps = 40, gamma=1, verbose=1)\n",
    "    pretrain_agent(\n",
    "        student,\n",
    "        exp_train = exp_train,\n",
    "        exp_test = exp_test,\n",
    "        epochs=1,\n",
    "        scheduler_gamma=0.7,\n",
    "        learning_rate=1.0,\n",
    "        log_interval=1000,\n",
    "        no_cuda=False,\n",
    "        seed=1,\n",
    "        batch_size=64)\n",
    "    student.policy.float()\n",
    "    student.learn(50000)\n",
    "    student.save('obs_orig/easy_0.1_128_50k')\n",
    "else:\n",
    "    # load existing model\n",
    "    student = PPO.load('obs_orig/mix_reward_0.1_PN64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complimentary-relief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 run time evalution env found\n",
      "40 run time evalution env found\n",
      "60 run time evalution env found\n",
      "80 run time evalution env found\n",
      "100 run time evalution env found\n"
     ]
    }
   ],
   "source": [
    "## runtime evaluation \n",
    "runtime_env_num = 100\n",
    "ob_num = 10\n",
    "limit = np.array([10,20])\n",
    "opt_num = 10\n",
    "sup_dim = 0\n",
    "# generate run time evaluation environments\n",
    "random.seed(1)\n",
    "time_env_list1 = []\n",
    "count = 0\n",
    "while(count < runtime_env_num):\n",
    "    done1 = False \n",
    "    done = False\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    obs = env_try.reset()\n",
    "    for j in range(100):\n",
    "        x0 = x0 - 0.1*env_try.obj.ob_der_fun(x0)\n",
    "        if env_try.obj.collision(x0):\n",
    "            done1 = True\n",
    "            break\n",
    "    for k in range(100):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_try.step(action)\n",
    "        if done:\n",
    "            break\n",
    "    if done1 and done and j > 10:\n",
    "        time_env_list1.append(env_try)\n",
    "        count += 1\n",
    "        if count%20 == 0:\n",
    "            print(count,'run time evalution env found')\n",
    "    env_try.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2557759284973145 1.9830152988433838\n",
      "===========================================================\n",
      "\n",
      "GD success rate: 1.0 GD average iterations= 28.59\n",
      "RL success rate: 1.0 RL average iterations= 20.23\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env = time_env_list1[1]\n",
    "x0 = env.obj.initial()\n",
    "obs = env.reset()\n",
    "ob_der_fun = env.obj.ob_der_fun\n",
    "t1 = time.time()\n",
    "for j in range(1000):\n",
    "    x0 = x0 - lr*ob_der_fun(x0)\n",
    "t_gd = time.time()-t1\n",
    "t1 = time.time()\n",
    "for j in range(1000):\n",
    "    action, _ = student.predict(obs, deterministic=True)\n",
    "    env.pos = action.reshape(10,2) + env.pos\n",
    "\n",
    "    current_der = env.obj.ob_der_fun(env.pos).flatten()\n",
    "    current_cost = env.environment.cost_fun(env.pos).flatten()\n",
    "    current_cost_value = np.array([np.mean(current_cost)])\n",
    "    obs = np.concatenate((current_der, current_cost, current_cost_value), axis=0).astype(np.float32)\n",
    "        \n",
    "t_rl = time.time()-t1\n",
    "print(t_gd,t_rl)\n",
    "runtime(student, time_env_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sapphire-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hard cases for test found\n",
      "2 hard cases for test found\n",
      "3 hard cases for test found\n",
      "4 hard cases for test found\n",
      "5 hard cases for test found\n",
      "6 hard cases for test found\n",
      "7 hard cases for test found\n",
      "8 hard cases for test found\n",
      "9 hard cases for test found\n",
      "10 hard cases for test found\n",
      "11 hard cases for test found\n",
      "12 hard cases for test found\n",
      "13 hard cases for test found\n",
      "14 hard cases for test found\n",
      "15 hard cases for test found\n",
      "16 hard cases for test found\n",
      "17 hard cases for test found\n",
      "18 hard cases for test found\n",
      "19 hard cases for test found\n",
      "20 hard cases for test found\n",
      "21 hard cases for test found\n",
      "22 hard cases for test found\n",
      "23 hard cases for test found\n",
      "24 hard cases for test found\n",
      "25 hard cases for test found\n",
      "26 hard cases for test found\n",
      "27 hard cases for test found\n",
      "28 hard cases for test found\n",
      "29 hard cases for test found\n",
      "30 hard cases for test found\n",
      "31 hard cases for test found\n",
      "32 hard cases for test found\n",
      "33 hard cases for test found\n",
      "34 hard cases for test found\n",
      "35 hard cases for test found\n",
      "36 hard cases for test found\n",
      "37 hard cases for test found\n",
      "38 hard cases for test found\n",
      "39 hard cases for test found\n",
      "40 hard cases for test found\n",
      "41 hard cases for test found\n",
      "42 hard cases for test found\n",
      "43 hard cases for test found\n",
      "44 hard cases for test found\n",
      "45 hard cases for test found\n",
      "46 hard cases for test found\n",
      "47 hard cases for test found\n",
      "48 hard cases for test found\n",
      "49 hard cases for test found\n",
      "50 hard cases for test found\n",
      "51 hard cases for test found\n",
      "52 hard cases for test found\n",
      "53 hard cases for test found\n",
      "54 hard cases for test found\n",
      "55 hard cases for test found\n",
      "56 hard cases for test found\n",
      "57 hard cases for test found\n",
      "58 hard cases for test found\n",
      "59 hard cases for test found\n",
      "60 hard cases for test found\n",
      "61 hard cases for test found\n",
      "62 hard cases for test found\n",
      "63 hard cases for test found\n",
      "64 hard cases for test found\n",
      "65 hard cases for test found\n",
      "66 hard cases for test found\n",
      "67 hard cases for test found\n",
      "68 hard cases for test found\n",
      "69 hard cases for test found\n",
      "70 hard cases for test found\n",
      "71 hard cases for test found\n",
      "72 hard cases for test found\n",
      "73 hard cases for test found\n",
      "74 hard cases for test found\n",
      "75 hard cases for test found\n",
      "76 hard cases for test found\n",
      "77 hard cases for test found\n",
      "78 hard cases for test found\n",
      "79 hard cases for test found\n",
      "80 hard cases for test found\n",
      "81 hard cases for test found\n",
      "82 hard cases for test found\n",
      "83 hard cases for test found\n",
      "84 hard cases for test found\n",
      "85 hard cases for test found\n",
      "86 hard cases for test found\n",
      "87 hard cases for test found\n",
      "88 hard cases for test found\n",
      "89 hard cases for test found\n",
      "90 hard cases for test found\n",
      "91 hard cases for test found\n",
      "92 hard cases for test found\n",
      "93 hard cases for test found\n",
      "94 hard cases for test found\n",
      "95 hard cases for test found\n",
      "96 hard cases for test found\n",
      "97 hard cases for test found\n",
      "98 hard cases for test found\n",
      "99 hard cases for test found\n",
      "100 hard cases for test found\n"
     ]
    }
   ],
   "source": [
    "# successful rate evaluation\n",
    "env_test_easy_num = 1000\n",
    "env_test_hard_num = 100\n",
    "\n",
    "# generate easy test environments\n",
    "random.seed(2)\n",
    "env_test_easy_list1 = []\n",
    "for i in range(env_test_easy_num):\n",
    "    env_test_easy_list1.append(generate_env(ob_num,limit,opt_num,0))\n",
    "# generate hard test environments\n",
    "env_test_hard_list1 = []\n",
    "count = 0\n",
    "while(count<env_test_hard_num):\n",
    "    env_try = generate_env(ob_num,limit,opt_num,sup_dim)\n",
    "    x0 = env_try.obj.initial()\n",
    "    free = False\n",
    "    for j in range(200):\n",
    "        x0 = x0 - lr*env_try.obj.ob_der_fun(x0)\n",
    "        if env_try.obj.collision(x0):\n",
    "            free = True\n",
    "            break\n",
    "    if not free:\n",
    "        env_test_hard_list1.append(env_try)\n",
    "        count += 1\n",
    "        print(count,'hard cases for test found')\n",
    "    env_try.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "double-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 complete\n",
      "0.1 complete\n",
      "0.15 complete\n",
      "0.2 complete\n",
      "0.25 complete\n",
      "0.3 complete\n",
      "0.35 complete\n",
      "0.4 complete\n",
      "0.45 complete\n",
      "0.5 complete\n",
      "0.55 complete\n",
      "0.6 complete\n",
      "0.65 complete\n",
      "0.7 complete\n",
      "0.75 complete\n",
      "0.8 complete\n",
      "0.85 complete\n",
      "0.9 complete\n",
      "0.95 complete\n",
      "1.0 complete\n",
      "result_list_easy: [0.744 0.153 0.082 0.021]\n",
      "success_rl: 82.60%\n",
      "success_gd: 76.50%\n"
     ]
    }
   ],
   "source": [
    "### easy test benchmark ###\n",
    "n_steps = 200\n",
    "lr = 0.1\n",
    "result_easy = np.zeros((4,))\n",
    "i = 0\n",
    "for env_test in env_test_easy_list1:\n",
    "    obs = env_test.reset()\n",
    "    x0 = env_test.pos\n",
    "    for step in range(n_steps):\n",
    "        x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "    for step in range(n_steps):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_test.step(action)\n",
    "        if done:\n",
    "            #print(\"Goal reached!\", \"reward=\", reward,\"step=\",step)\n",
    "            break\n",
    "    if done and env_test.obj.collision(x0):\n",
    "        result_easy[0] += 1\n",
    "    if not done and not env_test.obj.collision(x0):\n",
    "        result_easy[1] += 1\n",
    "    if done and not env_test.obj.collision(x0):\n",
    "        result_easy[2] += 1\n",
    "    if not done and env_test.obj.collision(x0):\n",
    "        result_easy[3] += 1\n",
    "    env_test.close()\n",
    "    if (i+1) % 50 == 0:\n",
    "        print((i+1)/len(env_test_easy_list1),'complete')\n",
    "    i += 1\n",
    "result_easy /= len(env_test_easy_list1)\n",
    "print(\"result_list_easy:\", result_easy)\n",
    "rl_success = result_easy[0]+result_easy[2]\n",
    "gd_success = result_easy[0]+result_easy[3]\n",
    "print('success_rl: %.2f%%'  % (rl_success*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chicken-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_list_hard_GD 0.0\n",
      "result_list_hard_RL 0.29\n"
     ]
    }
   ],
   "source": [
    "### hard test benchmark ###\n",
    "n_steps = 200\n",
    "lr = 0.1\n",
    "result_hard_GD = 0\n",
    "result_hard_RL = 0\n",
    "for env_test in env_test_hard_list1:\n",
    "    obs = env_test.reset()\n",
    "    x0 = env_test.pos\n",
    "    for step in range(n_steps):\n",
    "        x0 = x0 - lr * env_test.obj.ob_der_fun(x0)\n",
    "        if env_test.obj.collision(x0):\n",
    "            result_hard_GD += 1\n",
    "            break\n",
    "            \n",
    "    for step in range(n_steps):\n",
    "        action, _ = student.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env_test.step(action)\n",
    "        if done:\n",
    "            result_hard_RL += 1\n",
    "            break\n",
    "    env_test.close()\n",
    "result_hard_GD /= len(env_test_hard_list1)\n",
    "result_hard_RL /= len(env_test_hard_list1)\n",
    "print(\"result_list_hard_GD\", result_hard_GD)\n",
    "print(\"result_list_hard_RL\", result_hard_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "negative-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 complete\n",
      "0.1 complete\n",
      "0.15 complete\n",
      "0.2 complete\n",
      "0.25 complete\n",
      "0.3 complete\n",
      "0.35 complete\n",
      "0.4 complete\n",
      "0.45 complete\n",
      "0.5 complete\n",
      "0.55 complete\n",
      "0.6 complete\n",
      "0.65 complete\n",
      "0.7 complete\n",
      "0.75 complete\n",
      "0.8 complete\n",
      "0.85 complete\n",
      "0.9 complete\n",
      "0.95 complete\n",
      "1.0 complete\n",
      "result_list_easy_ms: [0.83  0.088 0.066 0.016]\n",
      "success_rl: 89.60% \n",
      "success_gd: 84.60%\n"
     ]
    }
   ],
   "source": [
    "### multi start on easy test benchmark\n",
    "multi_start_num = 5\n",
    "result_multi_start = np.zeros((4,))\n",
    "\n",
    "count = 0\n",
    "for env_test in env_test_easy_list1:\n",
    "    GD = False\n",
    "    RL = False\n",
    "    i=0\n",
    "    while(GD==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "            if env_test.obj.collision(x0):\n",
    "                GD = True\n",
    "                # print('GD finds feasible solution with',i,'trials on',count,'th environment')\n",
    "                break\n",
    "        i += 1\n",
    "    i=0\n",
    "    while(RL==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            action, _ = student.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env_test.step(action)\n",
    "            if done:\n",
    "                RL = True\n",
    "                # print('RL finds feasible solution with',i,'trials on',count,'th environment')\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    if GD == True and RL == True:\n",
    "        result_multi_start[0] += 1\n",
    "    elif GD == False and RL == False:\n",
    "        result_multi_start[1] += 1\n",
    "    elif GD == False and RL == True:\n",
    "        result_multi_start[2] += 1\n",
    "    else: \n",
    "        result_multi_start[3] += 1\n",
    "    if (count+1) % 50 == 0:\n",
    "        print((count+1)/len(env_test_easy_list1),'complete')\n",
    "    count += 1\n",
    "    env_test.close()\n",
    "    \n",
    "result_multi_start /= len(env_test_easy_list1)\n",
    "print(\"result_list_easy_ms:\", result_multi_start)\n",
    "rl_success_multi = result_multi_start[0]+result_multi_start[2]\n",
    "gd_success_multi = result_multi_start[0]+result_multi_start[3]\n",
    "print('success_rl: %.2f%% ' % (rl_success_multi*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success_multi*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "differential-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 complete\n",
      "1.0 complete\n",
      "result_list_hard_ms: [0.24 0.45 0.28 0.03]\n",
      "success_rl: 52.00% \n",
      "success_gd: 27.00%\n"
     ]
    }
   ],
   "source": [
    "### multi start on hard test benchmark ###\n",
    "multi_start_num = 5\n",
    "result_multi_start = np.zeros((4,))\n",
    "\n",
    "count = 0\n",
    "for env_test in env_test_hard_list1:\n",
    "    GD = False\n",
    "    RL = False\n",
    "    i=0\n",
    "    while(GD==False and i<multi_start_num):\n",
    "        if i == 0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            x0 = x0 - lr*env_test.obj.ob_der_fun(x0)\n",
    "            if env_test.obj.collision(x0):\n",
    "                GD = True\n",
    "                break\n",
    "        i += 1\n",
    "    i=0\n",
    "    while(RL==False and i<multi_start_num):\n",
    "        if i ==0:\n",
    "            obs = env_test.reset()\n",
    "        else:\n",
    "            obs = env_test.reset(random_start = True)\n",
    "        x0 = env_test.pos\n",
    "        for step in range(n_steps):\n",
    "            action, _ = student.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env_test.step(action)\n",
    "            if done:\n",
    "                RL = True\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    if GD == True and RL == True:\n",
    "        result_multi_start[0] += 1\n",
    "    elif GD == False and RL == False:\n",
    "        result_multi_start[1] += 1\n",
    "    elif GD == False and RL == True:\n",
    "        result_multi_start[2] += 1\n",
    "    else: \n",
    "        result_multi_start[3] += 1\n",
    "    if (count+1) % 50 == 0:\n",
    "        print((count+1)/len(env_test_hard_list1),'complete')\n",
    "    count += 1\n",
    "    env_test.close()\n",
    "    \n",
    "result_multi_start /= len(env_test_hard_list1)\n",
    "print(\"result_list_hard_ms:\", result_multi_start)\n",
    "rl_success_multi = result_multi_start[0]+result_multi_start[2]\n",
    "gd_success_multi = result_multi_start[0]+result_multi_start[3]\n",
    "print('success_rl: %.2f%% ' % (rl_success_multi*100))\n",
    "print('success_gd: %.2f%%'  % (gd_success_multi*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-thompson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-narrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-meter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-diesel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-boring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
