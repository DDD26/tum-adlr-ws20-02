{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADLR",
      "provenance": [],
      "authorship_tag": "ABX9TyOZiffpLltdzJJOw93S6EHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDD26/tum-adlr-ws20-02/blob/main/RI%20demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-6T86b7q5SQ",
        "outputId": "853217df-7c1b-4a47-ff00-60e79f646295"
      },
      "source": [
        "### install stable-baseline3 package ###\n",
        "!pip install stable-baselines3[extra]\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/7c/ec89fd9a51c2ff640f150479069be817136c02f02349b5dd27a6e3bb8b3d/stable_baselines3-0.10.0-py3-none-any.whl (145kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 10.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17 in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (1.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (1.7.0+cu101)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
            "Requirement already satisfied: tensorboard; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (2.3.0)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]) (0.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable-baselines3[extra]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable-baselines3[extra]) (1.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines3[extra]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines3[extra]) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3[extra]) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3[extra]) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3[extra]) (0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (0.35.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (0.4.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]) (50.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"extra\"->stable-baselines3[extra]) (3.1.0)\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-0.10.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Err:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.7_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfxD64Zk_tz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56b01d4-cdb6-4ec7-ccfa-4aad9f0e62e4"
      },
      "source": [
        "### import ###\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.ndimage as ndimage\n",
        "import torch\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO, A2C, SAC # DQN coming soon\n",
        "from stable_baselines3.common.cmd_util import make_vec_env\n",
        "from stable_baselines3.common.env_checker import check_env"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/stable_baselines3/common/cmd_util.py:6: FutureWarning: Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\n",
            "  \"Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmtEyEr4rCmN"
      },
      "source": [
        "### define our robot environment ###\n",
        "class Environment():\n",
        "    def __init__(self, pos, size, bound, voxel_size = np.array([0.1,0.1]), eps=1, order=1):\n",
        "        \"\"\"\n",
        "        Args: \n",
        "            pos: np array with shape [N,2], with N being number of obstacles, indicating coordinate of obstacle'slower left corner\n",
        "            size: np array with shape [N,2], with N being number of obstacles, indicating width and hight of obstacles\n",
        "            bound: np array with shape [2,], upper boundary of the work space. Lower bound is implicitly (0,0)\n",
        "            voxel_size: np array with shape [2,], voxel_size in x and y direction\n",
        "            eps: scalar, parameter in cost function\n",
        "            order: positive int, interpolation order\n",
        "        \"\"\"\n",
        "        self.pos = pos.astype(int)\n",
        "        self.size = size.astype(int)\n",
        "        self.bound = bound.astype(int)\n",
        "        self.voxel_size = voxel_size\n",
        "        self.ob_num = pos.shape[0]\n",
        "        self.eps = eps\n",
        "        self.order = order \n",
        "        \n",
        "        self.obstacle = self.obstacle()\n",
        "        self.dis = self.dis() \n",
        "        self.dis_der = self.dis_der()\n",
        "        self.dis_fun = self.dis_fun1()\n",
        "        self.dis_der_fun = self.dis_der_fun1()\n",
        "        self.cost_fun = self.cost_fun1()\n",
        "        self.cost_der_fun = self.cost_der_fun1()\n",
        "                \n",
        "    def obstacle(self):\n",
        "        \"\"\"\n",
        "        Geometric shape of the environment \n",
        "        Returns: \n",
        "            obstacle: a boolean numpy array with shape [bound[0],bound[1]], True indicates obstacle, False indicates free \n",
        "        \"\"\"\n",
        "        pos = self.pos\n",
        "        size = self.size \n",
        "        bound = self.bound\n",
        "        obstacle = np.zeros(bound,dtype = bool)\n",
        "        for i in range(pos.shape[0]):\n",
        "            low_left = pos[i]\n",
        "            up_right = low_left + size[i]\n",
        "            obstacle[tuple(map(slice, low_left, up_right))] = True\n",
        "        return obstacle \n",
        "    \n",
        "    def dis(self):\n",
        "        \"\"\"\n",
        "        Create nearest distance field, negative indicates inside obstacle\n",
        "        Returns: \n",
        "            dis: a float numpy array with shape [bound[0],bound[1]]\n",
        "        \"\"\"\n",
        "        bound = self.bound\n",
        "        voxel_size = self.voxel_size \n",
        "        \n",
        "        im = self.obstacle\n",
        "            \n",
        "        pad = np.ones(self.bound+2, dtype=bool)\n",
        "        pad[1:bound[0]+1,1:bound[1]+1] = im    \n",
        "            \n",
        "        dis = ndimage.distance_transform_edt(-pad.astype(int) + 1, sampling=voxel_size)\n",
        "        dis1 = ndimage.distance_transform_edt(pad.astype(int), sampling=voxel_size)\n",
        "        dis[pad] = - dis1[pad]  # Add interior information\n",
        "            \n",
        "        dis = dis[1:bound[0]+1,1:bound[1]+1]\n",
        "        return dis\n",
        "    \n",
        "    def dis_der(self):\n",
        "        \"\"\"\n",
        "        Applying sobel filter to nearest distance field to get and x and y gradient field \n",
        "        Returns: \n",
        "            dis_der: a float numpy array with shape [2,bound[0],bound[1]], dis_der[0] x gradient and dis_der[1] y gradient \n",
        "        \"\"\"\n",
        "        dis_der = np.zeros((2,self.bound[0],self.bound[1]),dtype=np.float64)\n",
        "        for d in range(2):  # Treat image boundary like obstacle\n",
        "            dis_der[d, ...] = ndimage.sobel(self.dis, axis=d, mode='constant', cval=0)/self.voxel_size[d]\n",
        "        return dis_der\n",
        "    \n",
        "    def dis_fun1(self):\n",
        "        \"\"\"\n",
        "        Interpolate the nearest distance to get distance function\n",
        "        Returns: \n",
        "            dis_fun: a function whose input is float numpy array with shape [N,2], N is number of inquiry points\n",
        "                                      output is float numpy array with shape [N,], respecting cost of each inquiry points\n",
        "        \"\"\" \n",
        "        factor = 1/self.voxel_size\n",
        "        im = self.dis\n",
        "        def dis_fun(x):\n",
        "            x = np.multiply(x,factor)-0.5\n",
        "            out = ndimage.map_coordinates(im, coordinates=x.T, order=self.order, mode='nearest')\n",
        "            return out          \n",
        "        return dis_fun\n",
        "    \n",
        "    def dis_der_fun1(self):\n",
        "        \"\"\"\n",
        "        Interpolate the x and y gradient field to get distance gradient function\n",
        "        Returns: \n",
        "            dis_der_fun: a function whose input is float numpy array with shape [N,2], N is number of inquiry points\n",
        "                                          output is float numpy array with shape [N,2], respecting x and y gradient of each point\n",
        "        \"\"\" \n",
        "        der = self.dis_der\n",
        "        factor = 1/self.voxel_size\n",
        "        def dis_der_fun(x):\n",
        "            x = np.multiply(x,factor)-0.5\n",
        "            gx = ndimage.map_coordinates(der[0,...], coordinates=x.T, order=self.order, mode='nearest')\n",
        "            gy = ndimage.map_coordinates(der[1,...], coordinates=x.T, order=self.order, mode='nearest')\n",
        "            return np.stack((gx,gy),axis=0).T\n",
        "        return dis_der_fun\n",
        "    \n",
        "    def cost_fun1(self):\n",
        "        \"\"\"\n",
        "        Assign cost to nearest distance field\n",
        "        Returns: \n",
        "            cost_fun: a function whose input is float numpy array with shape [N,2], N is number of inquiry points\n",
        "                                       output is float numpy array with shape [N,], cost of each point\n",
        "        \"\"\"\n",
        "        eps = self.eps\n",
        "        def cost_fun(x):\n",
        "            dis = self.dis_fun(x)\n",
        "            cost = np.zeros(dis.shape,dtype=np.float64)\n",
        "            cost[dis>eps] = 0\n",
        "            cost[np.logical_and(dis>0,dis<=eps)] = np.square(dis[np.logical_and(dis>0,dis<=eps)]-eps)/(2*eps)\n",
        "            cost[dis<=0] = eps/2 - dis[dis<=0]\n",
        "            return cost\n",
        "        return cost_fun\n",
        "\n",
        "    def cost_der_fun1(self):\n",
        "        \"\"\"\n",
        "        Assign cost gradient\n",
        "        Returns: \n",
        "            cost_der_fun: a function whose input is float numpy array with shape [N,2], N is number of inquiry points\n",
        "                                           output is float numpy array with shape [N,2], x and y cost gradient of each point\n",
        "        \"\"\"\n",
        "        eps = self.eps\n",
        "        def cost_der_fun(x):\n",
        "            dis = self.dis_fun(x)\n",
        "            dis_der = self.dis_der_fun(x)\n",
        "            der = cost = np.zeros((len(dis),2),dtype=np.float64)\n",
        "            der[dis>eps] = 0\n",
        "            der[np.logical_and(dis>0,dis<=eps)] = np.multiply((dis[np.logical_and(dis>0,dis<=eps)]-eps),dis_der[np.logical_and(dis>0,dis<=eps)].T).T/eps\n",
        "            der[dis<=0] = - dis_der[dis<0]\n",
        "            return der \n",
        "        return cost_der_fun\n",
        " \n",
        "class Objective():\n",
        "    def __init__(self,start, end, opt_num, sp_num,co_num, environment,w):\n",
        "        \"\"\"\n",
        "        Args: \n",
        "            start: np array with shape [2,], start point coordinate of the robot\n",
        "            end: np: array with shape [2,], end point coordinate of the robot\n",
        "            opt_num: number of optimization points \n",
        "            sp_num: number of subsampling points on line segements between two optimization points for calculating objective\n",
        "            co_num: number of subsampling points on line segements between two optimization points for collision check\n",
        "            environment: environment the objective function based on\n",
        "            w: weight term for length objective \n",
        "        \"\"\"\n",
        "        self.start = start \n",
        "        self.end = end\n",
        "        self.opt_num = opt_num \n",
        "        self.sp_num = sp_num\n",
        "        self.co_num = co_num\n",
        "        self.environment = environment\n",
        "        self.w = w  #length weight \n",
        "        \n",
        "        self.ob_fun = self.ob_fun1()\n",
        "        self.ob_der_fun = self.ob_der_fun1()\n",
        "        \n",
        "        \n",
        "    def ob_fun1(self):\n",
        "        \"\"\"\n",
        "        Given a trajectory, calculate its obstacle cost and length cost and objective \n",
        "        Returns: \n",
        "            ob_fun: a function whose input is float numpy array with shape [opt_num, 2]\n",
        "                                     output is float numpy scalar, the objective value\n",
        "        \"\"\"\n",
        "        env = self.environment\n",
        "        w = self.w\n",
        "        start = self.start\n",
        "        end = self.end\n",
        "        def ob_fun(x):\n",
        "            x1 = self.all_points(x,self.sp_num)\n",
        "            x1 = np.delete(x1,0,0)\n",
        "            x1 = np.delete(x1,x1.shape[0]-1,0)\n",
        "            return np.mean(env.cost_fun(x1)) + w*np.sum(np.diff(np.insert(x,(0,x.shape[0]),(start,end),axis=0),axis=0)**2)\n",
        "        return ob_fun\n",
        "    \n",
        "    def ob_der_fun1(self):\n",
        "        \"\"\"\n",
        "        Derivative of objective function\n",
        "        Returns: \n",
        "            ob_der_fun: a function whose input is a float numpy array with shape [opt_num, 2]\n",
        "                                         output is a float numpy array with shape [opt_num,2], the derivative \n",
        "        \"\"\"\n",
        "        env = self.environment\n",
        "        w = self.w\n",
        "        opt_num = self.opt_num\n",
        "        sp_num = self.sp_num\n",
        "        def ob_der_fun(x):\n",
        "            ### gradient of obstacle cost ###\n",
        "            x1 = self.all_points(x,self.sp_num)\n",
        "            x1 = np.delete(x1,0,0)\n",
        "            x1 = np.delete(x1,x1.shape[0]-1,0)\n",
        "            x1 = self.environment.cost_der_fun(x1)\n",
        "            x1 = torch.Tensor(x1).reshape(1,1,x1.shape[0],x1.shape[1])\n",
        "            kernel1 = np.append(np.arange(1,sp_num+2,1),np.arange(sp_num,0,-1))/(sp_num+1)\n",
        "            kernel1 = torch.Tensor(kernel1).reshape(1,1,kernel1.shape[0],1)\n",
        "            re1 = torch.nn.functional.conv2d(x1,kernel1,stride=(sp_num+1,1))\n",
        "            re1 = re1/(opt_num+(opt_num+1)*sp_num)\n",
        "            re1 = torch.squeeze(torch.squeeze(re1,0),0).numpy()\n",
        "            ### gradient of length cost ###\n",
        "            x2 = np.insert(x,(0,x.shape[0]),(start,end),axis=0)\n",
        "            x2 = torch.Tensor(x2).reshape(1,1,x2.shape[0],x2.shape[1])\n",
        "            kernel2 = torch.Tensor([-1,2,-1]).reshape(1,1,3,1)\n",
        "            re2 = 2*w*torch.nn.functional.conv2d(x2,kernel2,stride=1)\n",
        "            re2 = torch.squeeze(torch.squeeze(re2,0),0).numpy()\n",
        "            return re1+re2\n",
        "        return ob_der_fun\n",
        "    \n",
        "    def all_points(self,x,num):\n",
        "        \"\"\"\n",
        "        Combine all start, end, optimization and subsampling points (both for calculating objective and collision check)\n",
        "        Args:\n",
        "            x: float numpy array with shape [opt_num,2], optimization points\n",
        "            num: number of subsampling points\n",
        "        Returns: \n",
        "            x1: float numpy array with shape [opt_num+2+num*(opt_num+1), 2]\n",
        "        \"\"\"\n",
        "        start = self.start \n",
        "        end = self.end \n",
        "        x1 = np.insert(x,(0,x.shape[0]),(start,end),axis=0)\n",
        "        for i in range(x1.shape[0]-1):\n",
        "            x2 = np.linspace(x1[i+(num)*i],x1[i+1+(num)*i],num+1,endpoint=False)\n",
        "            x2 = np.delete(x2,0,0)\n",
        "            x1 = np.insert(x1,i+1+(num)*i,x2,axis=0)\n",
        "        return x1\n",
        "    \n",
        "    def initial(self):\n",
        "        \"\"\"\n",
        "        Initialize the trajectory by connecting start, end point and uniform sampling along this line segment\n",
        "        Returns: \n",
        "            x0: float numpy array with shape [opt_num, 2], initial optimization points\n",
        "        \"\"\"\n",
        "        x0 = np.linspace(self.start,self.end,self.opt_num+1,endpoint=False)\n",
        "        x0 = np.delete(x0,0,0)\n",
        "        return x0\n",
        "\n",
        "    def collision(self,x):\n",
        "        \"\"\"\n",
        "        Check if any of optimization and subsampling points collides with any of the obstacles. Moreover check if all points are in the boundary. \n",
        "        If both conditions are satisfied, returns True, otherwise False.    \n",
        "        \"\"\"\n",
        "        low = self.environment.pos\n",
        "        high = self.environment.pos + self.environment.size\n",
        "        x1 = self.all_points(x,self.co_num)\n",
        "        factor = 1/self.environment.voxel_size\n",
        "        x1 = np.multiply(x1,factor)-0.5\n",
        "        out = np.empty((x1.shape[0],),dtype=bool)\n",
        "        for i in range(x1.shape[0]):\n",
        "            k = np.concatenate((x1[i]>low,x1[i]<high),axis=1)\n",
        "            k = np.all(k,axis=1)\n",
        "            out[i] = np.any(k)\n",
        "            out1 = np.any(out)\n",
        "            out2 = np.all([x1>0,x1<self.environment.bound])\n",
        "        return not out1 and out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OasrNuAbrnws"
      },
      "source": [
        "### setup reinforcement learning environment ###\n",
        "class MPEnv(gym.Env):\n",
        "    def __init__(self,objective):\n",
        "        \"\"\"\n",
        "        Args: \n",
        "            objective: Objective object that the reinforcement learning framework is based on  \n",
        "        \"\"\"\n",
        "        super(MPEnv, self).__init__()\n",
        "        self.obj = objective                                                                                     # objective function that RI is based on\n",
        "        self.environment = self.obj.environment                                                                  # robot environment that RI is based on\n",
        "        self.at_space_dim = self.obj.opt_num*2                                                                   # action space dimension\n",
        "        self.action_space = spaces.Box(low = -10, high = 10, shape=(self.at_space_dim,),dtype=np.float32)      \n",
        "        self.history_num = 1                                                                                     # how many historical trajectory does the observation based on\n",
        "        self.warp_dim = 2*self.obj.opt_num                                                                       # dimension of observation that generated from one historical trajectory, \n",
        "                                                                                                                 # now we consider only gradient for easier training, \n",
        "                                                                                                                 #in future we can add objective value and coordinate\n",
        "        self.ob_space_dim = self.history_num*self.warp_dim                                                       # total dimension of observation space, start, end point coordinate not included,\n",
        "                                                                                                                 # may add that in future\n",
        "        self.observation_space = spaces.Box(low=-40, high = 40, shape=(self.ob_space_dim,), dtype=np.float32)\n",
        "        self.pos = self.obj.initial()                                                                            # coordinate of the trajectory with shape [opt_num, 2], the state for RI\n",
        "        self.observation = None\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        initialize the trajectory, return the observation initial state     \n",
        "        \"\"\"\n",
        "        self.pos = self.obj.initial()\n",
        "        start = self.obj.start\n",
        "        end = self.obj.end\n",
        "        initial_der = self.obj.ob_der_fun(self.pos).flatten()\n",
        "        initial_ob_val = np.array([self.obj.ob_fun(x0)])                                   # not used if history_num == 1\n",
        "        history = np.zeros((self.history_num-1)*(1+4*self.obj.opt_num),dtype=np.float32)   # not used if history_num == 1\n",
        "        self.observation = np.concatenate((history,initial_der),axis=0).astype(np.float32)\n",
        "        return self.observation\n",
        "    \n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Conduct the given action, go to the next state and return new observation, immdiate reward, additional info and check if goal is reached\n",
        "        PS: done is actually useless for training, because reward is not depend on done, unlike other RI cases\n",
        "        \"\"\"\n",
        "        self.pos = self.pos + action.reshape(self.obj.opt_num,2)\n",
        "        self.pos = np.clip(self.pos,0,self.environment.bound*self.environment.voxel_size)\n",
        "\n",
        "        new_observation = obj.ob_der_fun(self.pos).flatten()\n",
        "        self.observation = np.delete(self.observation,range(0, self.warp_dim)) # not used if history_num == 1 \n",
        "        self.observation = np.concatenate((self.observation,new_observation),axis=0).astype(np.float32)  # not used if history_num == 1\n",
        "        done = bool(self.obj.collision(self.pos))\n",
        "        reward = -self.obj.ob_fun(self.pos)\n",
        "        info = {}\n",
        "        return self.observation, reward, done, info\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcBrWE5Xt8Ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "582c1b07-80e6-416e-a4c1-bb2237fb61c8"
      },
      "source": [
        "### gradient descent demo ###\n",
        "\n",
        "## all input of robot environment ## \n",
        "pos = np.array([[10,10],[40,50],[15,35]])\n",
        "size = np.array([[20,20],[10,30],[20,30]])\n",
        "bound = np.array([64,64])\n",
        "start = np.array([0.1,0.1])\n",
        "end = np.array([6.3,6.3])\n",
        "opt_num = 5\n",
        "sp_num = 5\n",
        "co_num = 20\n",
        "w = 0.1\n",
        "environment = Environment(pos,size,bound)\n",
        "obj = Objective(start, end, opt_num, sp_num, co_num, environment, w)\n",
        "ob_fun = obj.ob_fun\n",
        "ob_der_fun = obj.ob_der_fun\n",
        "## all input of robot environment ##\n",
        "\n",
        "## gradient descent ##\n",
        "iter_num = 200\n",
        "lr = 0.2\n",
        "x0 = obj.initial()\n",
        "\n",
        "for i in range(iter_num):\n",
        "    x0 = x0 - lr*ob_der_fun(x0)\n",
        "    # print(x0) # \n",
        "b = environment.dis\n",
        "plt.imshow(b)\n",
        "print(obj.collision(x0))\n",
        "print(\"cost=\",obj.ob_fun(x0))\n",
        "x0 = x0*10-0.5\n",
        "print(x0)\n",
        "plt.plot(x0[:,1],x0[:,0])\n",
        "## gradient descent ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "cost= 1.684025889024842\n",
            "[[17.85976795  4.73879648]\n",
            " [34.55897202  6.17323945]\n",
            " [42.22355162 18.97576142]\n",
            " [48.28911555 31.86560151]\n",
            " [54.18445807 45.0084291 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f395469b5c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCUTbSB3cTdI",
        "outputId": "b861f304-51f4-40cb-e440-badd2fe57418"
      },
      "source": [
        "### reinforcement demo -- training ###\n",
        "env = MPEnv(obj)\n",
        "check_env(env, warn=True)\n",
        "model = PPO('MlpPolicy', env, gamma=1, verbose=1).learn(10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/stable_baselines3/common/env_checker.py:232: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 137  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 14   |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 131         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013005665 |\n",
            "|    clip_fraction        | 0.174       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -14.2       |\n",
            "|    explained_variance   | -1.3e+04    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.92e+04    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0261     |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 6.4e+04     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 129        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 47         |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02528485 |\n",
            "|    clip_fraction        | 0.172      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -14.2      |\n",
            "|    explained_variance   | -106       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.77e+04   |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0283    |\n",
            "|    std                  | 0.998      |\n",
            "|    value_loss           | 6.06e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 128          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067881667 |\n",
            "|    clip_fraction        | 0.144        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -14.1        |\n",
            "|    explained_variance   | -74.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.81e+04     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0266      |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 3.73e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 128         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016672924 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -14.1       |\n",
            "|    explained_variance   | -710        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.36e+04    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.029      |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 3.04e+04    |\n",
            "-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HBg0S2Jrvfvu",
        "outputId": "1d076151-a340-46c1-d2a2-cc20eb2ab86f"
      },
      "source": [
        "### reinforcement learning demo -- test ###\n",
        "obs = env.reset()\n",
        "# env.pos = 6.4*np.random.rand(env.obj.opt_num,2)    # this two lines enables different initialization at test time \n",
        "# obs = env.obj.ob_der_fun(env.pos).flatten()        # this two lines enables different initialization at test time \n",
        "print(\"initial cost=\",env.obj.ob_fun(env.pos))\n",
        "print(\"initial location\",env.pos)\n",
        "n_steps = 200\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print(\"step=\",step,env.obj.collision(env.pos),env.obj.ob_fun(env.pos))\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward,\"step=\",step)\n",
        "    break\n",
        "x = env.pos\n",
        "plt.imshow(environment.dis)\n",
        "x = x*10-0.5\n",
        "print(x)\n",
        "plt.plot(x.T[1],x.T[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial cost= 1.7575723518825996\n",
            "initial location [[1.13333333 1.13333333]\n",
            " [2.16666667 2.16666667]\n",
            " [3.2        3.2       ]\n",
            " [4.23333333 4.23333333]\n",
            " [5.26666667 5.26666667]]\n",
            "step= 0 False 1.7516772354327639\n",
            "step= 1 False 1.802172612957711\n",
            "step= 2 False 1.8512662616594755\n",
            "step= 3 False 1.8801821467943953\n",
            "step= 4 False 1.9056610177576747\n",
            "step= 5 False 1.9284724565500384\n",
            "step= 6 False 1.9479126398468118\n",
            "step= 7 False 1.9619266620372784\n",
            "step= 8 False 1.9742845498295902\n",
            "step= 9 False 1.9887910226489498\n",
            "step= 10 False 2.006602188497394\n",
            "step= 11 False 2.0280320663451263\n",
            "step= 12 False 2.0539503285417764\n",
            "step= 13 False 2.082497869622271\n",
            "step= 14 False 2.112637110506115\n",
            "step= 15 False 2.1427681886770746\n",
            "step= 16 False 2.171385722277777\n",
            "step= 17 False 2.2002299584472182\n",
            "step= 18 False 2.230003933582253\n",
            "step= 19 False 2.259643811039273\n",
            "step= 20 False 2.2898043045878334\n",
            "step= 21 False 2.319964576630618\n",
            "step= 22 False 2.3496323441287577\n",
            "step= 23 False 2.3778642833510117\n",
            "step= 24 False 2.4065805610388695\n",
            "step= 25 False 2.435675059638454\n",
            "step= 26 False 2.4622705773499556\n",
            "step= 27 False 2.486157526452597\n",
            "step= 28 False 2.505853801326692\n",
            "step= 29 False 2.5255595690798573\n",
            "step= 30 False 2.5443284246213613\n",
            "step= 31 False 2.5632030375178596\n",
            "step= 32 False 2.582775620208043\n",
            "step= 33 False 2.6016321691584636\n",
            "step= 34 False 2.6210351938628\n",
            "step= 35 False 2.640843299276666\n",
            "step= 36 False 2.65964013140183\n",
            "step= 37 False 2.6760368622773014\n",
            "step= 38 False 2.691434215279002\n",
            "step= 39 False 2.7093678809036423\n",
            "step= 40 False 2.7286976784717365\n",
            "step= 41 False 2.7470642941761776\n",
            "step= 42 False 2.758494763131128\n",
            "step= 43 False 2.759526916388201\n",
            "step= 44 False 2.747535216373826\n",
            "step= 45 False 2.739230430515026\n",
            "step= 46 False 2.736344383686229\n",
            "step= 47 False 2.727637483386166\n",
            "step= 48 False 2.7058519122262865\n",
            "step= 49 False 2.676715239032607\n",
            "step= 50 False 2.6554107446425568\n",
            "step= 51 False 2.640956853903801\n",
            "step= 52 False 2.6230245607415466\n",
            "step= 53 False 2.596083906312251\n",
            "step= 54 False 2.566133004828613\n",
            "step= 55 False 2.5482570346796827\n",
            "step= 56 False 2.5415578338108795\n",
            "step= 57 False 2.534455957118924\n",
            "step= 58 False 2.517928085536763\n",
            "step= 59 False 2.5047293879500687\n",
            "step= 60 False 2.507288139034591\n",
            "step= 61 False 2.5204356686561558\n",
            "step= 62 True 2.532625472110435\n",
            "Goal reached! reward= -2.532625472110435 step= 62\n",
            "[[21.87456529  5.05990428]\n",
            " [45.15296308 18.96740032]\n",
            " [59.25241992 43.90792   ]\n",
            " [60.77279491 60.39290424]\n",
            " [62.61001697 63.5       ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f38e8b37668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3hWclVU2AMw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckd--w0wpFrQ"
      },
      "source": [
        "Conclusion: \n",
        "1. PPO is more promising than A2C and SAC because with 1000 iteration training, PPO is able to find collision free path very stably.\n",
        "2. The default environment is relative simple, if additional obstacle with pos=[35,5] size = [30,20] is added, 1000 iteration PPO doesn't work while gradient descent can find feasible solution\n",
        "3. Although PPO agent can find feasible solution, if we let the agent further conduct its policy, the solution maybe infeasible again. However, if the objective function is 10 dim quadratic function, agent just oscillate in neighborhood of 0.\n",
        "4. Feasible solution found by PPO agent normally has a high cost.\n",
        "5. Pure reinforcement learning is only suitable for low dimensional optimization problem"
      ]
    }
  ]
}